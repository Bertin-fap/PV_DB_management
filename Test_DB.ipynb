{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "687a177a",
   "metadata": {},
   "source": [
    "# References\n",
    "- https://www.w3schools.com/sql/sql_intro.asp\n",
    "- O'REILLY Learning SQL Generate, Manipulate, and Retrieve Data Alan Beaulieu\n",
    "- O'REILLY Using SQLITE Jay A. Kreibich\n",
    "\n",
    "Programmes:\n",
    "- https://sqlitebrowser.org/\n",
    "- https://www.youtube.com/watch?v=wGqVjwNpBxY  SQLITE en ligne de commandes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d5c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global affectation\n",
    "\n",
    "DATABASE_NAME = 'essai.db'\n",
    "ATELIERS = ['MEP','Wet','PECVD','PVD','Serig','Sinton']\n",
    "FOLDER = r'C:\\Users\\franc\\PyVenv\\PV_DB_management'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a905514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2sqlite(dataframe, path_db=None, tbl_name=\"import\"):\n",
    "\n",
    "    '''The function df2sqlite converts a dataframe into a squlite database.\n",
    "    \n",
    "    Args:\n",
    "       dataframe (panda.DataFrame): the dataframe to convert in a data base\n",
    "       path_db (Path): full pathname of the database\n",
    "       tbl_name (str): name of the table\n",
    "    '''\n",
    "    \n",
    "    # Standard library imports\n",
    "    import sqlite3\n",
    "    \n",
    "    # 3rd party imports\n",
    "    import pandas as pd\n",
    "    \n",
    "\n",
    "    if path_db is None:  # Connection to the database\n",
    "        conn = sqlite3.connect(\":memory:\")\n",
    "    else:\n",
    "        conn = sqlite3.connect(path_db)\n",
    "        \n",
    "    # Creates a database and a table\n",
    "    cur = conn.cursor()\n",
    "    col_str = '\"' + '\",\"'.join(dataframe.columns) + '\"'\n",
    "    cur.execute(f\"CREATE TABLE IF NOT EXISTS {tbl_name} ({col_str})\")\n",
    "    dataframe.to_sql(tbl_name, conn, if_exists='replace', index = False)\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "def create_parsing_db():\n",
    "    \n",
    "    '''Convert the list of .csv file of the parsing FOLDER into a databae in which\n",
    "    each .csv file corresponds to a table.\n",
    "    \n",
    "    Args:\n",
    "       FOLDER (str): full path of de FOLDER parsing or filt_<i>\n",
    "    '''\n",
    "    \n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    for file in [file for file in os.listdir(FOLDER) if file.endswith('.xlsx')]:\n",
    "        df = pd.read_excel(os.path.join(FOLDER,file))\n",
    "        if len(df) > 0:\n",
    "            df2sqlite(df, path_db=os.path.join(FOLDER,DATABASE_NAME), tbl_name=file.split('.')[0])\n",
    "        else: \n",
    "            print(f'Warning: the file {file} is empty and will not be added to the database')\n",
    "\n",
    "def query_db(query):\n",
    "    \n",
    "    '''Sends a query to the database.\n",
    "    \n",
    "    Args:\n",
    "       query (str): the sql query\n",
    "       \n",
    "    Retuns:\n",
    "       The result of the query as a dataframe.\n",
    "    '''\n",
    "    \n",
    "    # Standard library import\n",
    "    import os\n",
    "    import sqlite3\n",
    "    \n",
    "    # 3rd party import\n",
    "    import pandas as pd\n",
    "    \n",
    "    conn = sqlite3.connect(os.path.join(FOLDER,DATABASE_NAME))\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        cur.execute(query)\n",
    "        \n",
    "    except sqlite3.OperationalError as e:\n",
    "        raise Exception(f'An errors has occured in the query: {e}')\n",
    "    else:\n",
    "        result_querry = {i:list(x) for i,x in enumerate(cur.fetchall())}\n",
    "        df = pd.DataFrame.from_dict(result_querry).T    \n",
    "    finally:  \n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def check_id_existance(table,PK):\n",
    "    \n",
    "    '''Returns True if the key PK allready exits in the table Returns False ortherwise.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Standard library import\n",
    "    import os\n",
    "    import sqlite3\n",
    "    from string import Template\n",
    "    \n",
    "    \n",
    "    conn = sqlite3.connect(os.path.join(FOLDER,DATABASE_NAME))\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    template = Template('''SELECT * FROM $table1\n",
    "                           WHERE  PK='$PK'\n",
    "                        ''')\n",
    "    id_exists = False\n",
    "    try:\n",
    "        cur.execute(template.substitute({'table1': table,\n",
    "                                         'PK': PK,}))\n",
    "    except sqlite3.OperationalError as e:\n",
    "        raise Exception(f'An errors has occured in the query: {e}')\n",
    "    else:\n",
    "        row = cur.fetchone() \n",
    "    finally:  \n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    \n",
    "    if row: \n",
    "        id_exists = True \n",
    "    else:\n",
    "        id_exists = False\n",
    "    return id_exists\n",
    "\n",
    "\n",
    "def insert_value(table,value):\n",
    "    \n",
    "    # Standard library import\n",
    "    import os\n",
    "    import sqlite3\n",
    "    from string import Template\n",
    "    \n",
    "    \n",
    "    conn = sqlite3.connect(os.path.join(FOLDER,DATABASE_NAME))\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    template = Template('''INSERT INTO $table\n",
    "                           VALUES $value\n",
    "                        ''')\n",
    "    \n",
    "    cur.execute(template.substitute({'table': table,\n",
    "                                     'value': value,}))\n",
    "    \n",
    "    conn.commit()\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "\n",
    "\n",
    "def delete_multiple_records(table,idList):\n",
    "    \n",
    "    # Standard library imports\n",
    "    import os\n",
    "    import sqlite3\n",
    "    from string import Template\n",
    "    \n",
    "    template = Template('''DELETE from $table\n",
    "                           WHERE PK = ?\n",
    "                        ''')\n",
    "    \n",
    "    try:\n",
    "        conn = sqlite3.connect(os.path.join(FOLDER,DATABASE_NAME))\n",
    "        cur = conn.cursor()\n",
    "        cur.executemany(template.substitute({'table': table,}),idList)\n",
    "        conn.commit()\n",
    "        print(\"Total\", cur.rowcount, \"Records deleted successfully\")\n",
    "        cur.close()\n",
    "\n",
    "    except sqlite3.Error as error:\n",
    "        print(\"Failed to delete multiple records from sqlite table\", error)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa6feecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the file Template_02.xlsx is empty and will not be added to the database\n"
     ]
    }
   ],
   "source": [
    "# Builds 6 fake excel files and a databse with six corresponding tables with N°Demande <= n_demandes\n",
    "\n",
    "# Standard library imports\n",
    "import datetime\n",
    "import itertools\n",
    "import random\n",
    "import string\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "\n",
    "# 3rd party imports\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "random_string_generator = lambda n:[''.join(random.choice(string.ascii_letters) for x in range(str_size)) for _ in range(n)]\n",
    " \n",
    "str_size = 12\n",
    " \n",
    "n_demandes = 500 # number of different demands\n",
    "for atelier in ATELIERS:\n",
    "    dic = {'N°demande':(n_demande := list(itertools.chain(*[[i]*random.randint(1,5) for i in range(n_demandes)]))),\n",
    "       'Version':[random.randint(0, 2) for _ in range(len(n_demande))],\n",
    "       'Split':[random.randint(0, 1) for _ in range(len(n_demande))],\n",
    "       'Date' : [(date.today() + datetime.timedelta(days=random.randint(0, 5))).isoformat() for _ in range(len(n_demande))],\n",
    "       'P1': np.random.normal(loc = 0.0, scale = 1.0, size = len(n_demande)),\n",
    "       'P2': np.random.normal(loc = 0.0, scale = 1.0, size = len(n_demande)),  \n",
    "       'P3': np.random.normal(loc = 0.0, scale = 1.0, size = len(n_demande)),\n",
    "       'P4': np.random.normal(loc = 0.0, scale = 1.0, size = len(n_demande)),\n",
    "       'PX': np.random.normal(loc = 0.0, scale = 1.0, size = len(n_demande)),\n",
    "       'Commentaire': random_string_generator(len(n_demande))}\n",
    "    \n",
    "    dg = pd.DataFrame.from_dict(dic)\n",
    "    dg = dg.drop_duplicates(['N°demande','Version','Split'])\n",
    "    dg['PK'] = dg.apply(lambda row:f'{row[0]}_{row[1]}_{row[2]}',axis=1)\n",
    "    dg.to_excel(Path(FOLDER) / Path(atelier+'.xlsx'),index=False)\n",
    "    \n",
    "create_parsing_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if if the primary key already exists\n",
    "\n",
    "PK = '2_1_0'\n",
    "for atelier in ATELIERS:\n",
    "    print(atelier,check_id_existance(atelier,PK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a new value in a table in and only if the primary key doesn't exist\n",
    "\n",
    "atelier = 'MEP'\n",
    "\n",
    "dic = {'N°demande':101,\n",
    "       'Version':1,\n",
    "       'Split':1,\n",
    "       'Date' : ( date.today() + datetime.timedelta(days=random.randint(0, 5))).isoformat(),\n",
    "       'P1': 0.1,\n",
    "       'P2': 0.1,  \n",
    "       'P3': 0.5,\n",
    "       'P4': 0.6,\n",
    "       'PX': 0.7,\n",
    "       }\n",
    "dic['PK'] = f\"{dic['N°demande']}_{dic['Version']}_{dic['Split']}\"\n",
    "\n",
    "if not check_id_existance(atelier,dic['PK']):\n",
    "\n",
    "    insert_value(atelier,tuple(dic.values()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ed211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete records from a table\n",
    "\n",
    "atelier = 'MEP'\n",
    "ids_to_delete = [('101_1_1',), ('0_1_1',), ('0_2_1',)]\n",
    "delete_multiple_records(atelier,ids_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7a1cbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SINTON_P1</th>\n",
       "      <th>MEP_P1</th>\n",
       "      <th>PECVD_P1</th>\n",
       "      <th>Wet_P2</th>\n",
       "      <th>MEP_PEK</th>\n",
       "      <th>Sinton_PK</th>\n",
       "      <th>PECVD_PK</th>\n",
       "      <th>Wet_PK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.794713</td>\n",
       "      <td>-1.027422</td>\n",
       "      <td>-1.400332</td>\n",
       "      <td>1.182185</td>\n",
       "      <td>83_0_0</td>\n",
       "      <td>83_0_0</td>\n",
       "      <td>83_0_0</td>\n",
       "      <td>83_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.123293</td>\n",
       "      <td>0.250772</td>\n",
       "      <td>0.428484</td>\n",
       "      <td>0.552821</td>\n",
       "      <td>116_0_1</td>\n",
       "      <td>116_0_1</td>\n",
       "      <td>116_0_1</td>\n",
       "      <td>116_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.615083</td>\n",
       "      <td>0.022209</td>\n",
       "      <td>1.101837</td>\n",
       "      <td>1.000308</td>\n",
       "      <td>162_1_1</td>\n",
       "      <td>162_1_1</td>\n",
       "      <td>162_1_1</td>\n",
       "      <td>162_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.194385</td>\n",
       "      <td>0.23165</td>\n",
       "      <td>-0.058578</td>\n",
       "      <td>1.904245</td>\n",
       "      <td>295_2_0</td>\n",
       "      <td>295_2_0</td>\n",
       "      <td>295_2_0</td>\n",
       "      <td>295_2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.615701</td>\n",
       "      <td>-0.784428</td>\n",
       "      <td>1.059565</td>\n",
       "      <td>0.634467</td>\n",
       "      <td>295_1_1</td>\n",
       "      <td>295_1_1</td>\n",
       "      <td>295_1_1</td>\n",
       "      <td>295_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.728823</td>\n",
       "      <td>-0.202104</td>\n",
       "      <td>0.574472</td>\n",
       "      <td>0.822755</td>\n",
       "      <td>308_0_0</td>\n",
       "      <td>308_0_0</td>\n",
       "      <td>308_0_0</td>\n",
       "      <td>308_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.299608</td>\n",
       "      <td>2.283395</td>\n",
       "      <td>-0.571412</td>\n",
       "      <td>0.547502</td>\n",
       "      <td>345_1_0</td>\n",
       "      <td>345_1_0</td>\n",
       "      <td>345_1_0</td>\n",
       "      <td>345_1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.52515</td>\n",
       "      <td>0.261233</td>\n",
       "      <td>-0.088461</td>\n",
       "      <td>0.821375</td>\n",
       "      <td>482_1_0</td>\n",
       "      <td>482_1_0</td>\n",
       "      <td>482_1_0</td>\n",
       "      <td>482_1_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SINTON_P1    MEP_P1  PECVD_P1    Wet_P2  MEP_PEK Sinton_PK PECVD_PK   Wet_PK\n",
       "0  1.794713 -1.027422 -1.400332  1.182185   83_0_0    83_0_0   83_0_0   83_0_0\n",
       "1  1.123293  0.250772  0.428484  0.552821  116_0_1   116_0_1  116_0_1  116_0_1\n",
       "2  0.615083  0.022209  1.101837  1.000308  162_1_1   162_1_1  162_1_1  162_1_1\n",
       "3  1.194385   0.23165 -0.058578  1.904245  295_2_0   295_2_0  295_2_0  295_2_0\n",
       "4  0.615701 -0.784428  1.059565  0.634467  295_1_1   295_1_1  295_1_1  295_1_1\n",
       "5  1.728823 -0.202104  0.574472  0.822755  308_0_0   308_0_0  308_0_0  308_0_0\n",
       "6  1.299608  2.283395 -0.571412  0.547502  345_1_0   345_1_0  345_1_0  345_1_0\n",
       "7   0.52515  0.261233 -0.088461  0.821375  482_1_0   482_1_0  482_1_0  482_1_0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select values\n",
    "# SELECT PECVD.PK, Sinton.PK, Sinton.P1 FROM PECVD  LEFT JOIN Sinton ON PECVD.PK=Sinton.PK\n",
    "#\n",
    "#CREATE VIEW SYNTHESIS AS \n",
    "#SELECT PK,P1,P2 FROM  PECVD;\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "query = '''SELECT \n",
    "              Sinton.P1 AS SINTON_P1,\n",
    "              MEP.P1 AS MEP_P1,\n",
    "              PECVD.P1 AS PECVD_P1,\n",
    "              Wet.P2 AS Wet_P2,\n",
    "              MEP.PK AS MEP_PEK,\n",
    "              Sinton.PK AS Sinton_PK,\n",
    "              PECVD.PK AS PECVD_PK,\n",
    "              Wet.PK AS Wet_PK\n",
    "           FROM \n",
    "              Sinton \n",
    "           JOIN MEP \n",
    "              ON Sinton.PK=MEP.PK \n",
    "           JOIN PECVD \n",
    "              ON Sinton.PK=PECVD.PK \n",
    "           JOIN Wet \n",
    "              ON Sinton.PK=Wet.PK\n",
    "           WHERE\n",
    "              Sinton.P1>0.5 AND Wet.P2>0.5\n",
    "        '''\n",
    "\n",
    "script = 'demo_tri.sql'\n",
    "sql_file = Path(FOLDER) / Path(script)\n",
    "with open(sql_file,'r') as file:\n",
    "    query = ''.join(file.readlines())\n",
    "\n",
    "df = query_db(query)\n",
    "df.columns = ['SINTON_P1',' MEP_P1','PECVD_P1','Wet_P2','MEP_PEK','Sinton_PK','PECVD_PK','Wet_PK']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb1195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorator(n):\n",
    "    def decorator_arguments(function):\n",
    "        def wrapper(*args):\n",
    "            for x in args:\n",
    "                print(f\" Arguments accepted are: {n*x}\")\n",
    "            return function(*args)\n",
    "\n",
    "        return wrapper\n",
    "    return decorator_arguments\n",
    "  \n",
    "@decorator(3)\n",
    "def add(a,b,d):\n",
    "    return a+b+d\n",
    "  \n",
    "def main():\n",
    "  \n",
    "    # the reference of wrapper_arguments\n",
    "    # is returned\n",
    "    add1 = add\n",
    "    print(add1)\n",
    "  \n",
    "    # passing the arguments to the \n",
    "    # wrapper_arguments\n",
    "    c = add(2,6,7)\n",
    "    print(c)\n",
    "  \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decorator_arguments(function):\n",
    "    def wrapper(*args):\n",
    "        for x in args:\n",
    "            print(f\" Arguments accepted are: {n*x}\")\n",
    "        return function(*args)\n",
    "\n",
    "    return wrapper\n",
    "    \n",
    "  \n",
    "@decorator_arguments\n",
    "def add(a,b,d):\n",
    "    return a+b+d\n",
    "  \n",
    "def main():\n",
    "  \n",
    "    # the reference of wrapper_arguments\n",
    "    # is returned\n",
    "    add1 = add\n",
    "    print(add1)\n",
    "  \n",
    "    # passing the arguments to the \n",
    "    # wrapper_arguments\n",
    "    c = add(2,6,7)\n",
    "    print(c)\n",
    "  \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6db1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PV_DB_m",
   "language": "python",
   "name": "pv_db_m"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
